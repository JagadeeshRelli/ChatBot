{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6cd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference: https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e92b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install NLTK: run pip install nltk\n",
    "#importing required libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "import string # to process standard python strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd1fb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using text from data science wikipidea page as the corpus\n",
    "#copy that text and save it in dstext.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3e53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8489ba59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jagad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f=open('dstext.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase\n",
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcd1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diplaying the sample of sent tokens and word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "284cf545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science\\nfrom wikipedia, the free encyclopedia\\njump to navigationjump to search\\nnot to be confused with information science.',\n",
       " 'the existence of comet neowise (here depicted as a series of red dots) was discovered by analyzing astronomical survey data acquired by a space telescope, the wide-field infrared survey explorer.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9347f4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'science']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "191a08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing the raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ceda273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3531fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e988ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83e4e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages to generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "953fe18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdc69d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function response that searches the user’s utterance for one or more general keywords\n",
    "#and returns one of several possible responses. If it doesn’t find the input matching any of the keywords,\n",
    "#it returns a response:” I am sorry! I don’t understand you.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3504cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7401b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic lines of code to feed the lines that we want our bot to say while starting\n",
    "#and ending a conversation, depending upon the user’s input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91b7d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT: My name is Bot. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
      "hi bot\n",
      "BOT: hi there\n",
      "what is data science?\n",
      "BOT: however, data science is different from computer science and information science.\n",
      "what are the foundations of data science?\n",
      "BOT: [4][5]\n",
      "\n",
      "\n",
      "contents\n",
      "1\tfoundations\n",
      "1.1\trelationship to statistics\n",
      "2\tetymology\n",
      "2.1\tearly usage\n",
      "2.2\tmodern usage\n",
      "3\timpact\n",
      "4\ttechnologies and techniques\n",
      "4.1\ttechniques\n",
      "5\tsee also\n",
      "6\treferences\n",
      "foundations\n",
      "data science is an interdisciplinary field focused on extracting knowledge from data sets, which are typically large (see big data), and applying the knowledge and actionable insights from data to solve problems in a wide range of application domains.\n",
      "what is its relationship with the statistics?\n",
      "BOT: [11]\n",
      "\n",
      "relationship to statistics\n",
      "many statisticians, including nate silver, have argued that data science is not a new field, but rather another name for statistics.\n",
      "bye\n",
      "BOT: Bye! take care..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"BOT: My name is Bot. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"BOT: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"BOT: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"BOT: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"BOT: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435f4de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa2852f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
